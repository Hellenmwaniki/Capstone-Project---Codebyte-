{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4731d587",
   "metadata": {},
   "source": [
    "# Merging the three sourced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f11cef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-878377d63e9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Read each file (assuming they are in the same directory as the notebook)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfile_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file_1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfile_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file_2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfile_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file_3.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file_1.csv'"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Read each file (assuming they are in the same directory as the notebook)\n",
    "file_1 = pd.read_csv('file_1.csv')\n",
    "file_2 = pd.read_csv('file_2.csv')\n",
    "file_3 = pd.read_csv('file_3.csv')\n",
    "\n",
    "# Concatenate the three DataFrames vertically (stacked row-wise)\n",
    "final_dataset = pd.concat([file_1, file_2, file_3], ignore_index=False)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "final_dataset.to_csv('final_dataset.csv', index=False)\n",
    "\n",
    "# Optional: Display the first few rows to confirm\n",
    "final_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0eb2bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f96c2e2bf8e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'file_1' is not defined"
     ]
    }
   ],
   "source": [
    "file_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b14985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111576, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22777dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_1.csv\n",
      "file_2.csv\n",
      "file_3.csv\n",
      "final_Dataset.csv\n",
      "merging_file.ipynb\n"
     ]
    }
   ],
   "source": [
    "# final_Dataset.shape\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9672332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded file_1.csv\n",
      "Successfully loaded file_2.csv\n",
      "Successfully loaded file_3.csv\n",
      "\n",
      "Successfully combined data into combined_data.csv\n",
      "Total rows in combined file: 111576\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Define the paths to your CSV files\n",
    "# file_paths = ['file_1.csv', 'file_2.csv', 'file_3.csv']\n",
    "# output_csv_name = 'combined_data.csv'\n",
    "\n",
    "# # Initialize an empty list to store dataframes\n",
    "# all_dataframes = []\n",
    "\n",
    "# # Loop through each file, read it into a pandas DataFrame, and append to the list\n",
    "# for file_path in file_paths:\n",
    "#     if os.path.exists(file_path):\n",
    "#         try:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             all_dataframes.append(df)\n",
    "#             print(f\"Successfully loaded {file_path}\")\n",
    "#         except pd.errors.EmptyDataError:\n",
    "#             print(f\"Warning: {file_path} is empty and will be skipped.\")\n",
    "#         except FileNotFoundError:\n",
    "#             print(f\"Error: {file_path} not found. Please check the path.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred while reading {file_path}: {e}\")\n",
    "#     else:\n",
    "#         print(f\"Error: {file_path} does not exist.\")\n",
    "\n",
    "# # Concatenate all dataframes into a single dataframe\n",
    "# if all_dataframes:\n",
    "#     combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "#     # Save the combined dataframe to a new CSV file\n",
    "#     combined_df.to_csv(output_csv_name, index=False)\n",
    "#     print(f\"\\nSuccessfully combined data into {output_csv_name}\")\n",
    "#     print(f\"Total rows in combined file: {len(combined_df)}\")\n",
    "# else:\n",
    "#     print(\"No dataframes were loaded. No combined CSV file was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b11b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.</th>\n",
       "      <th>0</th>\n",
       "      <th>Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\nWell, I thought we'd start with pronunciation, if that's okay with you.\\nNot the hacking and gagging and spitting part.  Please.\\nOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?</th>\n",
       "      <th>What an incredible victory. I agree the Kenyans should have been celebrated at the end. This was an incredible performance.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Who added the background music to the video it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>16:26  FEMI KUTI !!! RAAHHH !!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The greatest AI scam in history, is AI.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>if I only knew Siri is a mess, I would bought ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Maybe AI is just a fad like cryptos.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  \\\n",
       "0  2.0   \n",
       "1  3.0   \n",
       "2  4.0   \n",
       "3  5.0   \n",
       "4  6.0   \n",
       "\n",
       "  Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.  \\\n",
       "0  Who added the background music to the video it...                                                                                                                                                                  \n",
       "1                    16:26  FEMI KUTI !!! RAAHHH !!!                                                                                                                                                                  \n",
       "2            The greatest AI scam in history, is AI.                                                                                                                                                                  \n",
       "3  if I only knew Siri is a mess, I would bought ...                                                                                                                                                                  \n",
       "4               Maybe AI is just a fad like cryptos.                                                                                                                                                                  \n",
       "\n",
       "    0  \\\n",
       "0 NaN   \n",
       "1 NaN   \n",
       "2 NaN   \n",
       "3 NaN   \n",
       "4 NaN   \n",
       "\n",
       "  Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\nWell, I thought we'd start with pronunciation, if that's okay with you.\\nNot the hacking and gagging and spitting part.  Please.\\nOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?  \\\n",
       "0                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "1                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "2                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "3                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "4                                                NaN                                                                                                                                                                                                                                                                                                   \n",
       "\n",
       "  What an incredible victory. I agree the Kenyans should have been celebrated at the end. This was an incredible performance.  \n",
       "0                                                NaN                                                                           \n",
       "1                                                NaN                                                                           \n",
       "2                                                NaN                                                                           \n",
       "3                                                NaN                                                                           \n",
       "4                                                NaN                                                                           "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Step 1: Import necessary library\n",
    "# import pandas as pd\n",
    "\n",
    "# # Step 2: Read each CSV file\n",
    "# file_1 = pd.read_csv('file_1.csv')\n",
    "# file_2 = pd.read_csv('file_2.csv')\n",
    "# file_3 = pd.read_csv('file_3.csv')\n",
    "\n",
    "# # Step 3: Concatenate the files vertically\n",
    "# merged_df = pd.concat([file_1, file_2, file_3], ignore_index=True)\n",
    "\n",
    "# # Step 4: Save the result to a new CSV file\n",
    "# merged_df.to_csv('final_dataset.csv', index=False)\n",
    "\n",
    "# # Optional: Display the merged DataFrame\n",
    "# merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09593a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (111576, 5)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load each CSV file\n",
    "# df1 = pd.read_csv('file_1.csv')\n",
    "# df2 = pd.read_csv('file_2.csv')\n",
    "# df3 = pd.read_csv('file_3.csv')\n",
    "\n",
    "# # Concatenate the dataframes one below the other\n",
    "# merged_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# # Print the shape to confirm (should be like (100, 2))\n",
    "# print(\"Merged shape:\", merged_df.shape)\n",
    "\n",
    "# # Save the final dataset to a new CSV file\n",
    "# merged_df.to_csv('final_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25725ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Define the input file names in the desired order\n",
    "# input_files = ['file_1.csv', 'file_2.csv', 'file_3.csv']\n",
    "\n",
    "# # Define the name for the output combined CSV file\n",
    "# output_csv_name = 'combined_output_with_columns.csv'\n",
    "\n",
    "# # List to hold individual DataFrames\n",
    "# list_of_dfs = []\n",
    "\n",
    "# # Define the expected columns (for confirmation, not strictly necessary for concat)\n",
    "# expected_columns = ['column_ID', 'column_text']\n",
    "\n",
    "# # Loop through each specified file path\n",
    "# for file_name in input_files:\n",
    "#     if os.path.exists(file_name):\n",
    "#         try:\n",
    "#             # Read each CSV file into a pandas DataFrame\n",
    "#             df = pd.read_csv(file_name)\n",
    "\n",
    "#             # Optional: Check if columns match the expected columns (good practice for validation)\n",
    "#             if not all(col in df.columns for col in expected_columns):\n",
    "#                 print(f\"Warning: {file_name} does not contain all expected columns ({expected_columns}). Found: {df.columns.tolist()}\")\n",
    "#                 # You might choose to skip this file or handle column discrepancies here\n",
    "#                 # For this example, we'll proceed, assuming concat will handle missing columns with NaN\n",
    "\n",
    "#             list_of_dfs.append(df)\n",
    "#             print(f\"Successfully loaded {file_name}\")\n",
    "\n",
    "#         except pd.errors.EmptyDataError:\n",
    "#             print(f\"Warning: {file_name} is empty and will be skipped.\")\n",
    "#         except FileNotFoundError:\n",
    "#             print(f\"Error: {file_name} not found. Please ensure it's in the same directory or provide the full path.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred while reading {file_name}: {e}\")\n",
    "#     else:\n",
    "#         print(f\"Error: {file_name} does not exist. Please check the file name and path.\")\n",
    "\n",
    "# # Check if any dataframes were successfully loaded\n",
    "# if list_of_dfs:\n",
    "#     # Concatenate all dataframes in the order they were added to the list\n",
    "#     # Since the columns are identical, pandas will simply stack them.\n",
    "#     # If a file had an extra column, it would appear in the combined_df with NaN for other files.\n",
    "#     combined_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "#     # Reorder columns explicitly if you want to ensure column_ID comes before column_text\n",
    "#     # (This is only necessary if the input files had different column orders,\n",
    "#     # but pandas concat tries to preserve the order of the first DataFrame encountered for common columns)\n",
    "#     if all(col in combined_df.columns for col in expected_columns):\n",
    "#         combined_df = combined_df[expected_columns]\n",
    "#     else:\n",
    "#         print(\"Note: Not all expected columns were found in the combined data, skipping explicit column reordering.\")\n",
    "\n",
    "\n",
    "#     # Save the combined DataFrame to a new CSV file\n",
    "#     combined_df.to_csv(output_csv_name, index=False)\n",
    "\n",
    "#     print(f\"\\nSuccessfully combined data into '{output_csv_name}' in the specified order.\")\n",
    "#     print(f\"Total rows in combined file: {len(combined_df)}\")\n",
    "#     print(f\"Columns in combined file: {combined_df.columns.tolist()}\")\n",
    "# else:\n",
    "#     print(\"No CSV files were successfully loaded. No combined file was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd5d644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111578, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv(\"DATA.csv\", index_col = 0)\n",
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6d1fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who added the background music to the video it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16:26  FEMI KUTI !!! RAAHHH !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The greatest AI scam in history, is AI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>if I only knew Siri is a mess, I would bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maybe AI is just a fad like cryptos.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.\n",
       "1                                                                                                                                                                                                                  \n",
       "2  Who added the background music to the video it...                                                                                                                                                               \n",
       "3                    16:26  FEMI KUTI !!! RAAHHH !!!                                                                                                                                                               \n",
       "4            The greatest AI scam in history, is AI.                                                                                                                                                               \n",
       "5  if I only knew Siri is a mess, I would bought ...                                                                                                                                                               \n",
       "6               Maybe AI is just a fad like cryptos.                                                                                                                                                               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e5c9ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 111578 entries, 2 to 25628\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                             Non-Null Count   Dtype \n",
      "---  ------                                                                                                                                                                                                             --------------   ----- \n",
      " 0   Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.  111574 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5fed380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 111578 entries, 2 to 25628\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                             Non-Null Count   Dtype \n",
      "---  ------                                                                                                                                                                                                             --------------   ----- \n",
      " 0   Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.  111574 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379955e3",
   "metadata": {},
   "source": [
    "# Data Cleaning for NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b758a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (1.4.4)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: emoji in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas) (1.22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: typing_extensions>=4.7.0; python_version < \"3.9\" in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from emoji) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pandas nltk emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "164cf2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1247de65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run once\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db88a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load your data\n",
    "DF= pd.read_csv(\"DATA.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b17d1da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', 'Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fade7426",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-369a21ac6906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_emojis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: clean_text(x, keep_emojis=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7ad32f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who added the background music to the video it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16:26  FEMI KUTI !!! RAAHHH !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The greatest AI scam in history, is AI.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>if I only knew Siri is a mess, I would bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maybe AI is just a fad like cryptos.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.\n",
       "1                                                                                                                                                                                                                  \n",
       "2  Who added the background music to the video it...                                                                                                                                                               \n",
       "3                    16:26  FEMI KUTI !!! RAAHHH !!!                                                                                                                                                               \n",
       "4            The greatest AI scam in history, is AI.                                                                                                                                                               \n",
       "5  if I only knew Siri is a mess, I would bought ...                                                                                                                                                               \n",
       "6               Maybe AI is just a fad like cryptos.                                                                                                                                                               "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42be06a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', 'Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26108b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your text column (replace 'text' with your actual column name)\n",
    "print(df.columns)\n",
    "print(df['text'].head())  # adjust if your column has a different name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
