{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f07984e",
   "metadata": {},
   "source": [
    "## Team Members \n",
    "\n",
    "1. Jessica Mutiso\n",
    "2. Brian Waweru\n",
    "3. Pamela Godia\n",
    "4. Hellen Mwaniki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bcc01",
   "metadata": {},
   "source": [
    "## 1. Project Overview \n",
    "\n",
    "This project aims to develop a natural language chatbot capable of generating human-like responses and understanding informal customer feedback expressed in English, Kenyan Swahili and Sheng. Designed for a startup expanding into the Kenyan market, the chatbot will help the company engage users more naturally and analyze feedback from social platforms and online conversations. By training on locally relevant dialogue data  including YouTube comments and Kenyan media the system will capture the linguistic and cultural nuances often missed by standard models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee6a2e",
   "metadata": {},
   "source": [
    "## 1.1 Problem Statement\n",
    "Startups entering new markets often struggle to understand customer feedback when it's expressed in local dialects or informal language. In Kenya, much of this communication occurs in Swahili and Sheng, which combine local slang, English, and Swahili in a fluid, often unstructured manner. Existing chatbot systems trained on formal English fail to grasp the tone, intent, or meaning behind such messages. This project aims to fill that gap by building a chatbot trained specifically on real-world Kenyan conversations to interpret and respond to customer queries and feedback with local context and relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75c93e",
   "metadata": {},
   "source": [
    "## 1.2 Objectives\n",
    "\n",
    "- Collect and preprocess Kenyan user dialogue from YouTube, social media, and local content featuring Swahili and Sheng\n",
    "\n",
    "- Fine-tune the chatbot with foundational data for conversational structure, while emphasizing local language patterns\n",
    "\n",
    "- Build a sequence-to-sequence model  capable of handling informal, code-switched dialogue\n",
    "\n",
    "- Evaluate the chatbot’s performance with emphasis on contextual relevance and local understanding\n",
    "\n",
    "- Present a working prototype that simulates real customer feedback scenarios "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d69050",
   "metadata": {},
   "source": [
    "## 2. Youtube Data Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f51945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.176.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (2.40.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (2.25.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > \"3.0\" in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (2.4.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.2.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.4)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.25.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.10)\n"
     ]
    }
   ],
   "source": [
    "! pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f23775a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import csv\n",
    "\n",
    "# Replace with your YouTube API key\n",
    "API_KEY = 'AIzaSyAL-zoRJClDhT9CszYblZbf7CdmAn3NJxI'\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7809d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for video: qlZM3McwO1Q\n",
      "Fetching comments for video: -voTKRBOEd0\n",
      "Fetching comments for video: 7JwKc6r5fAQ\n",
      "Fetching comments for video: _b6D5wMzKZQ\n",
      "Fetching comments for video: IB12MAwLs58\n",
      "Fetching comments for video: QzIkndzWYU4\n",
      "Fetching comments for video: P0cwqhA-YCk\n",
      "Fetching comments for video: q4sWUJxjc4g\n",
      "\n",
      "Total comments collected: 25629\n"
     ]
    }
   ],
   "source": [
    "def get_comments_with_replies(video_id):\n",
    "    comments = []\n",
    "    \n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet,replies\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        while request:\n",
    "            for item in response.get(\"items\", []):\n",
    "                top_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comments.append({\"video_id\": video_id, \"comment\": top_comment})\n",
    "                \n",
    "                # Add replies if any\n",
    "                replies = item.get(\"replies\", {}).get(\"comments\", [])\n",
    "                for reply in replies:\n",
    "                    reply_text = reply[\"snippet\"][\"textDisplay\"]\n",
    "                    comments.append({\"video_id\": video_id, \"comment\": reply_text})\n",
    "            \n",
    "            # Pagination\n",
    "            if \"nextPageToken\" in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=100,\n",
    "                    pageToken=response[\"nextPageToken\"],\n",
    "                    textFormat=\"plainText\"\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    except HttpError as e:\n",
    "        print(f\"Failed to fetch comments for video {video_id}: {e}\")\n",
    "    \n",
    "    return comments\n",
    "\n",
    "# List of video IDs\n",
    "video_ids = [\n",
    "    'qlZM3McwO1Q',\n",
    "    '-voTKRBOEd0',\n",
    "    '7JwKc6r5fAQ',\n",
    "    '_b6D5wMzKZQ',\n",
    "    'IB12MAwLs58',\n",
    "    'QzIkndzWYU4',\n",
    "    'P0cwqhA-YCk',\n",
    "    'q4sWUJxjc4g'\n",
    "]\n",
    "\n",
    "# Collect comments for all videos\n",
    "all_comments = []\n",
    "\n",
    "for vid in video_ids:\n",
    "    print(f\"Fetching comments for video: {vid}\")\n",
    "    video_comments = get_comments_with_replies(vid)\n",
    "    all_comments.extend(video_comments)\n",
    "\n",
    "print(f\"\\nTotal comments collected: {len(all_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eebb639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comments exported to 'youtube_comments.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Export comments to a CSV file\n",
    "csv_filename = \"youtube_comments.csv\"\n",
    "\n",
    "if all_comments and isinstance(all_comments[0], dict):\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"video_id\", \"comment\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_comments)\n",
    "\n",
    "    print(f\"✅ Comments exported to '{csv_filename}' successfully.\")\n",
    "else:\n",
    "    print(\"⚠️ No structured comment data available to export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e60c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba8342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "df = pd.read_csv('youtube_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97692fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.9</td>\n",
       "      <td>62847</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m1</td>\n",
       "      <td>1492: conquest of paradise</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10421</td>\n",
       "      <td>['adventure', 'biography', 'drama', 'history']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m2</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.1</td>\n",
       "      <td>25854</td>\n",
       "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m3</td>\n",
       "      <td>2001: a space odyssey</td>\n",
       "      <td>1968</td>\n",
       "      <td>8.4</td>\n",
       "      <td>163227</td>\n",
       "      <td>['adventure', 'mystery', 'sci-fi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m4</td>\n",
       "      <td>48 hrs.</td>\n",
       "      <td>1982</td>\n",
       "      <td>6.9</td>\n",
       "      <td>22289</td>\n",
       "      <td>['action', 'comedy', 'crime', 'drama', 'thrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m5</td>\n",
       "      <td>the fifth element</td>\n",
       "      <td>1997</td>\n",
       "      <td>7.5</td>\n",
       "      <td>133756</td>\n",
       "      <td>['action', 'adventure', 'romance', 'sci-fi', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m6</td>\n",
       "      <td>8mm</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.3</td>\n",
       "      <td>48212</td>\n",
       "      <td>['crime', 'mystery', 'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m7</td>\n",
       "      <td>a nightmare on elm street 4: the dream master</td>\n",
       "      <td>1988</td>\n",
       "      <td>5.2</td>\n",
       "      <td>13590</td>\n",
       "      <td>['fantasy', 'horror', 'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>m8</td>\n",
       "      <td>a nightmare on elm street: the dream child</td>\n",
       "      <td>1989</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11092</td>\n",
       "      <td>['fantasy', 'horror', 'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m9</td>\n",
       "      <td>the atomic submarine</td>\n",
       "      <td>1959</td>\n",
       "      <td>4.9</td>\n",
       "      <td>513</td>\n",
       "      <td>['sci-fi', 'thriller']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1                                           col2  col3  col4    col5  \\\n",
       "0   m0                     10 things i hate about you  1999   6.9   62847   \n",
       "1   m1                     1492: conquest of paradise  1992   6.2   10421   \n",
       "2   m2                                     15 minutes  2001   6.1   25854   \n",
       "3   m3                          2001: a space odyssey  1968   8.4  163227   \n",
       "4   m4                                        48 hrs.  1982   6.9   22289   \n",
       "5   m5                              the fifth element  1997   7.5  133756   \n",
       "6   m6                                            8mm  1999   6.3   48212   \n",
       "7   m7  a nightmare on elm street 4: the dream master  1988   5.2   13590   \n",
       "8   m8     a nightmare on elm street: the dream child  1989   4.7   11092   \n",
       "9   m9                           the atomic submarine  1959   4.9     513   \n",
       "\n",
       "                                                col6  \n",
       "0                              ['comedy', 'romance']  \n",
       "1     ['adventure', 'biography', 'drama', 'history']  \n",
       "2           ['action', 'crime', 'drama', 'thriller']  \n",
       "3                 ['adventure', 'mystery', 'sci-fi']  \n",
       "4  ['action', 'comedy', 'crime', 'drama', 'thrill...  \n",
       "5  ['action', 'adventure', 'romance', 'sci-fi', '...  \n",
       "6                   ['crime', 'mystery', 'thriller']  \n",
       "7                  ['fantasy', 'horror', 'thriller']  \n",
       "8                  ['fantasy', 'horror', 'thriller']  \n",
       "9                             ['sci-fi', 'thriller']  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54999711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25629 entries, 0 to 25628\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video_id  25629 non-null  object\n",
      " 1   comment   25628 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 400.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# information of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2dadde",
   "metadata": {},
   "source": [
    "## Overall EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046223d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing relevant notebooks \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe29c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "\n",
      "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
      "\n",
      "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading movie_lines data \n",
    "\n",
    "with open('movie_lines.txt', encoding='utf-8') as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b43917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id,comment\n",
      "\n",
      "qlZM3McwO1Q,What an incredible victory. I agree the Kenyans should have been celebrated at the end. This was an incredible performance.\n",
      "\n",
      "qlZM3McwO1Q,❤\n",
      "\n",
      "qlZM3McwO1Q,“Claudia is an amazonian goddess with a beautiful clam!” - Bruce Wayne\n",
      "\n",
      "qlZM3McwO1Q,Proud of my motherland Kenya ❤❤❤and Africa.at large\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"youtube_comments.csv\", encoding=\"utf-8\") as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "252200e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Comment,Reply\n",
      "\n",
      "\"Apple missed the boat on AI OR... Apple is doing what it always does, waiting for others to prove a new technology, then ride in on their massive platform and take over. Time will tell which statement is true.\",\n",
      "\n",
      "\"Who added the background music to the video its so fucking distracting. It sounds like nier automata bgm, that makes it impossible to focus\",\n",
      "\n",
      "16:26  FEMI KUTI !!! RAAHHH !!!,\n",
      "\n",
      "\"The greatest AI scam in history, is AI.\",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open (\"data-from-youtube.csv\", encoding =\"utf-8\") as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5312de27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineID</th>\n",
       "      <th>characterID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L924</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>Wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L872</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L871</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L870</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L869</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Like my fear of wearing pastels?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lineID characterID movieID character  \\\n",
       "0  L1045          u0      m0    BIANCA   \n",
       "1  L1044          u2      m0   CAMERON   \n",
       "2   L985          u0      m0    BIANCA   \n",
       "3   L984          u2      m0   CAMERON   \n",
       "4   L925          u0      m0    BIANCA   \n",
       "5   L924          u2      m0   CAMERON   \n",
       "6   L872          u0      m0    BIANCA   \n",
       "7   L871          u2      m0   CAMERON   \n",
       "8   L870          u0      m0    BIANCA   \n",
       "9   L869          u0      m0    BIANCA   \n",
       "\n",
       "                                                text  \n",
       "0                                       They do not!  \n",
       "1                                        They do to!  \n",
       "2                                         I hope so.  \n",
       "3                                          She okay?  \n",
       "4                                          Let's go.  \n",
       "5                                                Wow  \n",
       "6     Okay -- you're gonna need to learn how to lie.  \n",
       "7                                                 No  \n",
       "8  I'm kidding.  You know how sometimes you just ...  \n",
       "9                   Like my fear of wearing pastels?  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['lineID', 'characterID', 'movieID', 'character', 'text']\n",
    "\n",
    "movie_lines_data = pd.read_csv(\n",
    "    'movie_lines.txt',\n",
    "    sep=' \\+\\+\\+\\$\\+\\+\\+ ',\n",
    "    engine='python',\n",
    "    names=columns,\n",
    "    encoding='ISO-8859-1'  \n",
    ")\n",
    "\n",
    "movie_lines_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f87b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Reading the conversation data\n",
    "\n",
    "with open(\"movie_conversations.txt\", encoding=\"ISO-8859-1\") as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b0471cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character1ID</th>\n",
       "      <th>character2ID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>utteranceIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198', 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204', 'L205', 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207', 'L208']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character1ID character2ID movieID                      utteranceIDs\n",
       "0           u0           u2      m0  ['L194', 'L195', 'L196', 'L197']\n",
       "1           u0           u2      m0                  ['L198', 'L199']\n",
       "2           u0           u2      m0  ['L200', 'L201', 'L202', 'L203']\n",
       "3           u0           u2      m0          ['L204', 'L205', 'L206']\n",
       "4           u0           u2      m0                  ['L207', 'L208']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['character1ID', 'character2ID', 'movieID', 'utteranceIDs']\n",
    "\n",
    "conversation_data = pd.read_csv(\n",
    "    \"movie_conversations.txt\",\n",
    "    sep=' \\+\\+\\+\\$\\+\\+\\+ ',\n",
    "    engine='python',\n",
    "    names=columns,\n",
    "    encoding='ISO-8859-1'\n",
    ")\n",
    "\n",
    "conversation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ff71c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u0 +++$+++ BIANCA +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ f +++$+++ 4\n",
      "\n",
      "u1 +++$+++ BRUCE +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ ? +++$+++ ?\n",
      "\n",
      "u2 +++$+++ CAMERON +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ m +++$+++ 3\n",
      "\n",
      "u3 +++$+++ CHASTITY +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ ? +++$+++ ?\n",
      "\n",
      "u4 +++$+++ JOEY +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ m +++$+++ 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading Movie_charaters data \n",
    "\n",
    "with open (\"movie_characters_metadata.txt\" ,encoding=\"ISO- 8859-1\") as f: \n",
    "    for _  in range(5):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c528d691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>characterID</th>\n",
       "      <th>name</th>\n",
       "      <th>movie</th>\n",
       "      <th>gender</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u0</th>\n",
       "      <td>BIANCA</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>f</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u1</th>\n",
       "      <td>BRUCE</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u2</th>\n",
       "      <td>CAMERON</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>m</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u3</th>\n",
       "      <td>CHASTITY</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u4</th>\n",
       "      <td>JOEY</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>m</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u5</th>\n",
       "      <td>KAT</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u6</th>\n",
       "      <td>MANDELLA</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u7</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>m</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u8</th>\n",
       "      <td>MISS PERKY</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u9</th>\n",
       "      <td>PATRICK</td>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   characterID name                       movie gender position\n",
       "u0      BIANCA   m0  10 things i hate about you      f        4\n",
       "u1       BRUCE   m0  10 things i hate about you      ?        ?\n",
       "u2     CAMERON   m0  10 things i hate about you      m        3\n",
       "u3    CHASTITY   m0  10 things i hate about you      ?        ?\n",
       "u4        JOEY   m0  10 things i hate about you      m        6\n",
       "u5         KAT   m0  10 things i hate about you      f        2\n",
       "u6    MANDELLA   m0  10 things i hate about you      f        7\n",
       "u7     MICHAEL   m0  10 things i hate about you      m        5\n",
       "u8  MISS PERKY   m0  10 things i hate about you      ?        ?\n",
       "u9     PATRICK   m0  10 things i hate about you      m        1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "columns = ['characterID', 'name', 'movie', 'gender', 'position']\n",
    "\n",
    "character_data = pd.read_csv(\n",
    "    \"movie_characters_metadata.txt\",\n",
    "    sep=' \\+\\+\\+\\$\\+\\+\\+ ',\n",
    "    engine='python',\n",
    "    names=columns,\n",
    "    encoding='ISO-8859-1'\n",
    ")\n",
    "\n",
    "character_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6438d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0 +++$+++ 10 things i hate about you +++$+++ 1999 +++$+++ 6.90 +++$+++ 62847 +++$+++ ['comedy', 'romance']\n",
      "\n",
      "m1 +++$+++ 1492: conquest of paradise +++$+++ 1992 +++$+++ 6.20 +++$+++ 10421 +++$+++ ['adventure', 'biography', 'drama', 'history']\n",
      "\n",
      "m2 +++$+++ 15 minutes +++$+++ 2001 +++$+++ 6.10 +++$+++ 25854 +++$+++ ['action', 'crime', 'drama', 'thriller']\n",
      "\n",
      "m3 +++$+++ 2001: a space odyssey +++$+++ 1968 +++$+++ 8.40 +++$+++ 163227 +++$+++ ['adventure', 'mystery', 'sci-fi']\n",
      "\n",
      "m4 +++$+++ 48 hrs. +++$+++ 1982 +++$+++ 6.90 +++$+++ 22289 +++$+++ ['action', 'comedy', 'crime', 'drama', 'thriller']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading movie titles data \n",
    "\n",
    "with open (\"movie_titles_metadata.txt\", encoding= \"ISO-8859-1\") as f:\n",
    "    for _ in range(5):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "423b4058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "      <th>no_votes</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.9</td>\n",
       "      <td>62847</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m1</td>\n",
       "      <td>1492: conquest of paradise</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10421</td>\n",
       "      <td>['adventure', 'biography', 'drama', 'history']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m2</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.1</td>\n",
       "      <td>25854</td>\n",
       "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m3</td>\n",
       "      <td>2001: a space odyssey</td>\n",
       "      <td>1968</td>\n",
       "      <td>8.4</td>\n",
       "      <td>163227</td>\n",
       "      <td>['adventure', 'mystery', 'sci-fi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m4</td>\n",
       "      <td>48 hrs.</td>\n",
       "      <td>1982</td>\n",
       "      <td>6.9</td>\n",
       "      <td>22289</td>\n",
       "      <td>['action', 'comedy', 'crime', 'drama', 'thrill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MovieID                 Movie Title  Year  Rating  no_votes  \\\n",
       "0      m0  10 things i hate about you  1999     6.9     62847   \n",
       "1      m1  1492: conquest of paradise  1992     6.2     10421   \n",
       "2      m2                  15 minutes  2001     6.1     25854   \n",
       "3      m3       2001: a space odyssey  1968     8.4    163227   \n",
       "4      m4                     48 hrs.  1982     6.9     22289   \n",
       "\n",
       "                                               Genre  \n",
       "0                              ['comedy', 'romance']  \n",
       "1     ['adventure', 'biography', 'drama', 'history']  \n",
       "2           ['action', 'crime', 'drama', 'thriller']  \n",
       "3                 ['adventure', 'mystery', 'sci-fi']  \n",
       "4  ['action', 'comedy', 'crime', 'drama', 'thrill...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"MovieID\", \"Movie Title\",\"Year\", \"Rating\", \"no_votes\", \"Genre\"]\n",
    "\n",
    "movie_titles = pd.read_csv(\n",
    "    \"movie_titles_metadata.txt\",\n",
    "    sep=' \\+\\+\\+\\$\\+\\+\\+ ',\n",
    "    engine='python',\n",
    "    names=columns,\n",
    "    encoding='ISO-8859-1'\n",
    ")\n",
    "\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16b749f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0 +++$+++ 10 things i hate about you +++$+++ http://www.dailyscript.com/scripts/10Things.html\n",
      "\n",
      "m1 +++$+++ 1492: conquest of paradise +++$+++ http://www.hundland.org/scripts/1492-ConquestOfParadise.txt\n",
      "\n",
      "m2 +++$+++ 15 minutes +++$+++ http://www.dailyscript.com/scripts/15minutes.html\n",
      "\n",
      "m3 +++$+++ 2001: a space odyssey +++$+++ http://www.scifiscripts.com/scripts/2001.txt\n",
      "\n",
      "m4 +++$+++ 48 hrs. +++$+++ http://www.awesomefilm.com/script/48hours.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading raw_script data\n",
    "\n",
    "with open (\"raw_script_urls.txt\", encoding = \"ISO-8859=1\") as f:\n",
    "        for _ in range(5):\n",
    "              print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba58eb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>no_votes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m0</td>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>1999</td>\n",
       "      <td>6.9</td>\n",
       "      <td>62847</td>\n",
       "      <td>['comedy', 'romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m1</td>\n",
       "      <td>1492: conquest of paradise</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10421</td>\n",
       "      <td>['adventure', 'biography', 'drama', 'history']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m2</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.1</td>\n",
       "      <td>25854</td>\n",
       "      <td>['action', 'crime', 'drama', 'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m3</td>\n",
       "      <td>2001: a space odyssey</td>\n",
       "      <td>1968</td>\n",
       "      <td>8.4</td>\n",
       "      <td>163227</td>\n",
       "      <td>['adventure', 'mystery', 'sci-fi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m4</td>\n",
       "      <td>48 hrs.</td>\n",
       "      <td>1982</td>\n",
       "      <td>6.9</td>\n",
       "      <td>22289</td>\n",
       "      <td>['action', 'comedy', 'crime', 'drama', 'thrill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movieID                       title  year  rating  no_votes  \\\n",
       "0      m0  10 things i hate about you  1999     6.9     62847   \n",
       "1      m1  1492: conquest of paradise  1992     6.2     10421   \n",
       "2      m2                  15 minutes  2001     6.1     25854   \n",
       "3      m3       2001: a space odyssey  1968     8.4    163227   \n",
       "4      m4                     48 hrs.  1982     6.9     22289   \n",
       "\n",
       "                                              genres  \n",
       "0                              ['comedy', 'romance']  \n",
       "1     ['adventure', 'biography', 'drama', 'history']  \n",
       "2           ['action', 'crime', 'drama', 'thriller']  \n",
       "3                 ['adventure', 'mystery', 'sci-fi']  \n",
       "4  ['action', 'comedy', 'crime', 'drama', 'thrill...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['movieID', 'title', 'year', 'rating', 'no_votes', 'genres']\n",
    "\n",
    "raw_script = pd.read_csv(\n",
    "    \"movie_titles_metadata.txt\",\n",
    "    sep=' \\+\\+\\+\\$\\+\\+\\+ ',\n",
    "    engine='python',\n",
    "    names=columns,\n",
    "    encoding='ISO-8859-1'\n",
    ")\n",
    "\n",
    "raw_script.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d0399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_lines.txt → Rows: 304713, Columns: 5\n",
      "movie_conversations.txt → Rows: 83097, Columns: 4\n",
      "movie_characters_metadata.txt → Rows: 9035, Columns: 5\n",
      "movie_titles_metadata.txt → Rows: 617, Columns: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of  dataset files and how many columns are in each\n",
    "files_info = {\n",
    "    \"movie_lines.txt\": 5,\n",
    "    \"movie_conversations.txt\": 4,\n",
    "    \"movie_characters_metadata.txt\": 5,\n",
    "    \"movie_titles_metadata.txt\": 6,  \n",
    "}\n",
    "\n",
    "# Matching delimiter\n",
    "delimiter = r' \\+\\+\\+\\$\\+\\+\\+ '\n",
    "\n",
    "for file, col_count in files_info.items():\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"{file} not found.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            sep=delimiter,\n",
    "            engine='python',\n",
    "            encoding='ISO-8859-1',\n",
    "            header=None,\n",
    "            names=[f'col{i+1}' for i in range(col_count)]\n",
    "        )\n",
    "        print(f\"{file} → Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b646dd",
   "metadata": {},
   "source": [
    "## Pairing conversion_data & movie_lines_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8056789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70683</th>\n",
       "      <td>I'll introduce you.</td>\n",
       "      <td>Ick.  And those foul chemicals in the pots--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93684</th>\n",
       "      <td>Yeah. Way north.</td>\n",
       "      <td>What unit were you with ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53506</th>\n",
       "      <td>So, is this like a Japanese restaurant?</td>\n",
       "      <td>I'd better get in there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129352</th>\n",
       "      <td>Jack.</td>\n",
       "      <td>Frank.  I'm here.  I always get here.  Don't s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88786</th>\n",
       "      <td>Only six?</td>\n",
       "      <td>What is this?  'Twenty Questions'?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68607</th>\n",
       "      <td>Let's talk about the work that you care so muc...</td>\n",
       "      <td>Sure.  Where would you like to start?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89187</th>\n",
       "      <td>Then what would be enough?  If we were married?</td>\n",
       "      <td>I wouldn't want you to marry me just to prove ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96887</th>\n",
       "      <td>This kind of heat. It's pathetic.</td>\n",
       "      <td>Well, I guess you pick your poison.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164927</th>\n",
       "      <td>Do you know where you're going ?</td>\n",
       "      <td>Yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99293</th>\n",
       "      <td>In a day or two, yes.</td>\n",
       "      <td>Eve is going to stay. The house will not be cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "70683                                 I'll introduce you.   \n",
       "93684                                    Yeah. Way north.   \n",
       "53506             So, is this like a Japanese restaurant?   \n",
       "129352                                              Jack.   \n",
       "88786                                           Only six?   \n",
       "68607   Let's talk about the work that you care so muc...   \n",
       "89187     Then what would be enough?  If we were married?   \n",
       "96887                   This kind of heat. It's pathetic.   \n",
       "164927                   Do you know where you're going ?   \n",
       "99293                               In a day or two, yes.   \n",
       "\n",
       "                                                 response  \n",
       "70683        Ick.  And those foul chemicals in the pots--  \n",
       "93684                           What unit were you with ?  \n",
       "53506                            I'd better get in there.  \n",
       "129352  Frank.  I'm here.  I always get here.  Don't s...  \n",
       "88786                  What is this?  'Twenty Questions'?  \n",
       "68607               Sure.  Where would you like to start?  \n",
       "89187   I wouldn't want you to marry me just to prove ...  \n",
       "96887                 Well, I guess you pick your poison.  \n",
       "164927                                               Yes.  \n",
       "99293   Eve is going to stay. The house will not be cl...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Safely converting strings that looks like lists into actual list objects \n",
    "\n",
    "def safe_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    return val\n",
    "\n",
    "conversation_data['utteranceIDs'] = conversation_data['utteranceIDs'].apply(safe_eval)\n",
    "import ast\n",
    "\n",
    "# a lookup dictionary from lineID → text\n",
    "line_map = dict(zip(movie_lines_data['lineID'], movie_lines_data['text']))\n",
    "\n",
    "# input–response pairs \n",
    "pairs = []\n",
    "for utterances in conversation_data['utteranceIDs']:\n",
    "    for i in range(len(utterances) - 1):\n",
    "        input_text = line_map.get(utterances[i])\n",
    "        response_text = line_map.get(utterances[i + 1])\n",
    "        if input_text and response_text:\n",
    "            pairs.append((input_text, response_text))\n",
    "\n",
    "# Converting to DataFrame\n",
    "dialogue_df = pd.DataFrame(pairs, columns=['input', 'response'])\n",
    "\n",
    "\n",
    "dialogue_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91c026",
   "metadata": {},
   "source": [
    "## Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b05385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               comment swahili_words  \\\n",
      "60                             Watu wa kasongo hoyeee.        [watu]   \n",
      "102  Alafu msichana wa watu akishakimbia hivi boyfr...        [watu]   \n",
      "281  Peperusha bendera nanii kenya 🇰🇪 to the world ...        [sana]   \n",
      "356  Amazing, watu wa nguvu, always doing Kenya proud.        [watu]   \n",
      "560                      Obiri and kipyego wee ni moto          [ni]   \n",
      "\n",
      "     swahili_word_count  \n",
      "60                    1  \n",
      "102                   1  \n",
      "281                   1  \n",
      "356                   1  \n",
      "560                   1  \n"
     ]
    }
   ],
   "source": [
    "# Generic set of common Swahili or Sheng words that the function will check for in the comments\n",
    "\n",
    "swahili_sheng_vocab = {\n",
    "    'watu', 'sana', 'ni', 'kweli', 'yaani', 'ndio', 'hapana', 'wewe',\n",
    "    'walicheza', 'fiti', 'mambo', 'uko', 'niko', 'bro', 'manze', 'nani',\n",
    "    'mbogi', 'gava', 'safi', 'poa', 'niko', 'shida', 'leo', 'kesho',\n",
    "    'mathe', 'buda', 'manze', 'dem', 'jamo', 'mpango', 'sijui', 'nashindwa'\n",
    "}\n",
    "\n",
    "\n",
    "# Function to extract Swahili/Sheng words\n",
    "\n",
    "def find_swahili_sheng(comment):\n",
    "    comment = re.sub(r'[^\\w\\s]', '', str(comment)).lower()\n",
    "    words_in_comment = comment.split()\n",
    "    swahili_words = [word for word in words_in_comment if word in swahili_sheng_vocab]\n",
    "    return swahili_words\n",
    "\n",
    "# Applying to DataFrame\n",
    "df['swahili_words'] = df['comment'].apply(find_swahili_sheng)\n",
    "df['swahili_word_count'] = df['swahili_words'].apply(len)\n",
    "\n",
    "# Filtering only those with Swahili/Sheng detected\n",
    "df_swahili = df[df['swahili_word_count'] > 0]\n",
    "\n",
    "print(df_swahili[['comment', 'swahili_words', 'swahili_word_count']].head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07bca2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>Yes sure the guardian angel in him was sending...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23454</th>\n",
       "      <td>My heart goes to serah,so sad,Abraham God is t...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23002</th>\n",
       "      <td>Serah is living every woman's greatest nightma...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>May he run mad and be a pain to himself and hi...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>Hugs mama God is with you,Justice for Kingsley!</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17389</th>\n",
       "      <td>this story  is hard.serah is not as she has sa...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20569</th>\n",
       "      <td>I wonder if the roles were reversed whether Ma...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157</th>\n",
       "      <td>May God give her strength the pain i too . Hav...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>How do someone kill a one year old child?😢😢</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>So so sad</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment     lang\n",
       "10624  Yes sure the guardian angel in him was sending...  english\n",
       "23454  My heart goes to serah,so sad,Abraham God is t...  english\n",
       "23002  Serah is living every woman's greatest nightma...  english\n",
       "10121  May he run mad and be a pain to himself and hi...  english\n",
       "9186     Hugs mama God is with you,Justice for Kingsley!  english\n",
       "17389  this story  is hard.serah is not as she has sa...  english\n",
       "20569  I wonder if the roles were reversed whether Ma...  english\n",
       "9157   May God give her strength the pain i too . Hav...  english\n",
       "2919         How do someone kill a one year old child?😢😢  english\n",
       "8907                                           So so sad  english"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Language detection function on Youtube_comments dataset\n",
    "\n",
    "def detect_language(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text)).lower()\n",
    "    tokens = text.split()\n",
    "    matches = sum(word in swahili_sheng_vocab for word in tokens)\n",
    "\n",
    "    if matches == 0:\n",
    "        return 'english'\n",
    "    elif matches >= 3:\n",
    "        return 'swahili_sheng'\n",
    "    else:\n",
    "        return 'mixed'\n",
    "\n",
    "# Applying to YouTube comments\n",
    "df['lang'] = df['comment'].apply(detect_language)\n",
    "\n",
    "df[['comment', 'lang']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed-language comments:\n",
      "                                               comment\n",
      "60                             Watu wa kasongo hoyeee.\n",
      "102  Alafu msichana wa watu akishakimbia hivi boyfr...\n",
      "281  Peperusha bendera nanii kenya 🇰🇪 to the world ...\n",
      "356  Amazing, watu wa nguvu, always doing Kenya proud.\n",
      "560                      Obiri and kipyego wee ni moto\n",
      "562      Moto aliyouwasha Kipyegon ulikuwa mambo yote.\n",
      "581  Congratulations to our athletic ladies,  l lov...\n",
      "637           Proud to be kenyan 🇰🇪🇰🇪🇰🇪🇰🇪kenya ni home\n",
      "655  .... und man sieht sogar auf dem ersten Blick ...\n",
      "700     Kama wewe n mkenya weka like tukisonga ❤❤❤🎉🎉🎉🎉\n"
     ]
    }
   ],
   "source": [
    "# Mixed language\n",
    "\n",
    "mixed_comments = df[df['lang'] == 'mixed']\n",
    "print(\"Mixed-language comments:\")\n",
    "print(mixed_comments[['comment']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fcbdff",
   "metadata": {},
   "source": [
    "## Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c763034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\helle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc591c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>clean_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11733</th>\n",
       "      <td>True...such a beast!</td>\n",
       "      <td>truesuch a beast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>The only winner is the man.</td>\n",
       "      <td>the only winner is the man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>Hapa iko shida Sarah got sooo hurt 🤕 she is st...</td>\n",
       "      <td>hapa iko shida sarah got sooo hurt  she is sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>Oooiiieee God will be your justice and your co...</td>\n",
       "      <td>oooiiieee god will be your justice and your co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22591</th>\n",
       "      <td>Allow me to say Abraham ni kadinya wa kawaida....</td>\n",
       "      <td>allow me to say abraham ni kadinya wa kawaidaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>LNN NGUGI is truly God sent 🙏 He shall carry y...</td>\n",
       "      <td>lnn ngugi is truly god sent  he shall carry yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23107</th>\n",
       "      <td>No One can love two women equally .it's a lie ...</td>\n",
       "      <td>no one can love two women equally its a lie ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>May  God give you strength</td>\n",
       "      <td>may  god give you strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20130</th>\n",
       "      <td>Nobody can love two ladies at same time never....</td>\n",
       "      <td>nobody can love two ladies at same time neverh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>May he never know any peace may the cry of his...</td>\n",
       "      <td>may he never know any peace may the cry of his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  \\\n",
       "11733                               True...such a beast!   \n",
       "16986                        The only winner is the man.   \n",
       "23087  Hapa iko shida Sarah got sooo hurt 🤕 she is st...   \n",
       "4977   Oooiiieee God will be your justice and your co...   \n",
       "22591  Allow me to say Abraham ni kadinya wa kawaida....   \n",
       "2664   LNN NGUGI is truly God sent 🙏 He shall carry y...   \n",
       "23107  No One can love two women equally .it's a lie ...   \n",
       "1572                          May  God give you strength   \n",
       "20130  Nobody can love two ladies at same time never....   \n",
       "10196  May he never know any peace may the cry of his...   \n",
       "\n",
       "                                           clean_comment  \n",
       "11733                                   truesuch a beast  \n",
       "16986                         the only winner is the man  \n",
       "23087  hapa iko shida sarah got sooo hurt  she is sti...  \n",
       "4977   oooiiieee god will be your justice and your co...  \n",
       "22591  allow me to say abraham ni kadinya wa kawaidaa...  \n",
       "2664   lnn ngugi is truly god sent  he shall carry yo...  \n",
       "23107  no one can love two women equally its a lie ad...  \n",
       "1572                          may  god give you strength  \n",
       "20130  nobody can love two ladies at same time neverh...  \n",
       "10196  may he never know any peace may the cry of his...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Youtube Data \n",
    "\n",
    "youtube_df = pd.read_csv('youtube_comments.csv')\n",
    "\n",
    "# Drop rows with missing comments\n",
    "youtube_df.dropna(subset=['comment'], inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "youtube_df.drop_duplicates(subset='comment', inplace=True)\n",
    "\n",
    "# Basic text cleaning function\n",
    "def clean_comment(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', str(text))  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)                       # Remove punctuation\n",
    "    text = text.lower()                                       # Lowercase\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning\n",
    "youtube_df['clean_comment'] = youtube_df['comment'].apply(clean_comment)\n",
    "\n",
    "# Check result\n",
    "youtube_df[['comment', 'clean_comment']].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "431df1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_clean</th>\n",
       "      <th>response_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217098</th>\n",
       "      <td>the thing is ill need a first mate</td>\n",
       "      <td>i know where you can find any number of naked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82110</th>\n",
       "      <td>im afraid thats not possible</td>\n",
       "      <td>why not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190678</th>\n",
       "      <td>what is it a military spacecraft like a shuttl...</td>\n",
       "      <td>something like that that doesnt surprise you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218077</th>\n",
       "      <td>hochmut</td>\n",
       "      <td>vain proud such a person is hochmutsnarr he is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193661</th>\n",
       "      <td>is it loaded</td>\n",
       "      <td>no i dont think so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31379</th>\n",
       "      <td>its probably going to need stitches</td>\n",
       "      <td>im going to throw up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64261</th>\n",
       "      <td>nick the ice is</td>\n",
       "      <td>get to the bridge hey hey down here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96206</th>\n",
       "      <td>think i got em</td>\n",
       "      <td>i dont know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194540</th>\n",
       "      <td>you could do it</td>\n",
       "      <td>i could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130460</th>\n",
       "      <td>such as</td>\n",
       "      <td>keeping an eye on dr duval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_clean  \\\n",
       "217098                 the thing is ill need a first mate   \n",
       "82110                        im afraid thats not possible   \n",
       "190678  what is it a military spacecraft like a shuttl...   \n",
       "218077                                            hochmut   \n",
       "193661                                       is it loaded   \n",
       "31379                 its probably going to need stitches   \n",
       "64261                                     nick the ice is   \n",
       "96206                                      think i got em   \n",
       "194540                                    you could do it   \n",
       "130460                                            such as   \n",
       "\n",
       "                                           response_clean  \n",
       "217098  i know where you can find any number of naked ...  \n",
       "82110                                             why not  \n",
       "190678       something like that that doesnt surprise you  \n",
       "218077  vain proud such a person is hochmutsnarr he is...  \n",
       "193661                                 no i dont think so  \n",
       "31379                                im going to throw up  \n",
       "64261                 get to the bridge hey hey down here  \n",
       "96206                                         i dont know  \n",
       "194540                                            i could  \n",
       "130460                         keeping an eye on dr duval  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dialogue Dataframe\n",
    "\n",
    "# Drop missing or null input/response\n",
    "dialogue_df.dropna(subset=['input', 'response'], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "dialogue_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", '', str(text))     # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)                 # Remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)                    # Remove extra spaces\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Apply cleaning to input and response\n",
    "dialogue_df['input_clean'] = dialogue_df['input'].apply(clean_text)\n",
    "dialogue_df['response_clean'] = dialogue_df['response'].apply(clean_text)\n",
    "\n",
    "# Remove rows where cleaned input or response is empty\n",
    "dialogue_df = dialogue_df[(dialogue_df['input_clean'] != '') & (dialogue_df['response_clean'] != '')]\n",
    "\n",
    "# Reset index\n",
    "dialogue_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dialogue_df[['input_clean', 'response_clean']].sample(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learn-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
