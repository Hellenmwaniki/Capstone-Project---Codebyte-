{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f07984e",
   "metadata": {},
   "source": [
    "## Team Members \n",
    "\n",
    "1. Jessica Mutiso\n",
    "2. Brian Waweru\n",
    "3. Pamela Godia\n",
    "4. Hellen Mwaniki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bcc01",
   "metadata": {},
   "source": [
    "## 1. Project Overview \n",
    "\n",
    "\n",
    "This project aims to develop a natural language chatbot that can generate human-like responses by learning from real-world conversations. Leveraging dialogue data from YouTube videos and movie scripts, the chatbot will be trained to understand conversational flow and context. The Cornell Movie Dialogues Corpus will serve as the primary training dataset, enabling the model to grasp nuances in dialogue structure, character interactions, and contextual relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee6a2e",
   "metadata": {},
   "source": [
    "## 1.1 Problem Statement\n",
    "Traditional rule-based chatbots often produce rigid, context-insensitive responses that break the natural flow of conversation. To build a more engaging and realistic conversational experience, this project will leverage deep learning techniques on real-world dialogue data. The goal is to develop a chatbot capable of understanding and generating coherent, context-aware responses in multi-turn conversations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75c93e",
   "metadata": {},
   "source": [
    "## 1.2 Objectives\n",
    "\n",
    "- Scrape and preprocess real dialogue data from YouTube and integrate it with the Cornell Movie Dialogues Corpus\n",
    "\n",
    "- Structure the dataset for effective training and evaluation\n",
    "\n",
    "- Train a sequence-to-sequence chatbot model using RNNs or LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d69050",
   "metadata": {},
   "source": [
    "## Youtube Data Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f51945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\helle\\anaconda3\\lib\\site-packages (2.176.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.25.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\helle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23775a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import csv\n",
    "\n",
    "# Replace with your YouTube API key\n",
    "API_KEY = 'AIzaSyAL-zoRJClDhT9CszYblZbf7CdmAn3NJxI'\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbba34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of video IDs you want to scrape; Add more as needed\n",
    "\n",
    "VIDEO_ID = 'qlZM3McwO1Q'\n",
    "\n",
    "# Initialize the YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84da6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch comments and replies\n",
    "def get_comments_with_replies(video_id):\n",
    "    all_comments = []\n",
    "\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet,replies\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100,\n",
    "        textFormat=\"plainText\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    while request:\n",
    "        for item in response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comment_thread = {\n",
    "                'top_comment': top_comment,\n",
    "                'replies': []\n",
    "            }\n",
    "\n",
    "            # Extract replies if they exist\n",
    "            if 'replies' in item:\n",
    "                for reply in item['replies']['comments']:\n",
    "                    reply_text = reply['snippet']['textDisplay']\n",
    "                    comment_thread['replies'].append(reply_text)\n",
    "\n",
    "            all_comments.append(comment_thread)\n",
    "\n",
    "        if 'nextPageToken' in response:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                textFormat=\"plainText\",\n",
    "                pageToken=response['nextPageToken']\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0b2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function and get data \n",
    "comments_data = get_comments_with_replies(VIDEO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23929f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Comments and replies saved to 'youtube_comments_replies.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the comments to a CSV file\n",
    "with open('youtube_comments_replies.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Top Comment', 'Reply'])\n",
    "\n",
    "    for item in comments_data:\n",
    "        if item['replies']:\n",
    "            for reply in item['replies']:\n",
    "                writer.writerow([item['top_comment'], reply])\n",
    "        else:\n",
    "            writer.writerow([item['top_comment'], ''])\n",
    "\n",
    "print(\"✅ Done! Comments and replies saved to 'youtube_comments_replies.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548d8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83bab6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('youtube_comments_replies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67914557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Comment</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well done team Kenya❤</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This channel is racist! Report the channel, it...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Congs Kenya, lots of love from Uganda</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just WOW Kenya, what a run, what a stamina!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm a south African love kenyans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Top Comment Reply\n",
       "0                              Well done team Kenya❤   NaN\n",
       "1  This channel is racist! Report the channel, it...   NaN\n",
       "2              Congs Kenya, lots of love from Uganda   NaN\n",
       "3        Just WOW Kenya, what a run, what a stamina!   NaN\n",
       "4                   I'm a south African love kenyans   NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5c6c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1088 entries, 0 to 1087\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Top Comment  1088 non-null   object\n",
      " 1   Reply        139 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 17.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
